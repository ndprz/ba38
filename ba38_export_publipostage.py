from flask import Blueprint, request, jsonify, current_app
from utils import envoyer_mail, get_google_services, write_log
import pandas as pd
import os
import re
import sqlite3
import unicodedata
import subprocess
import time
from gspread.exceptions import APIError

from googleapiclient.discovery import build


# ============================================================================
# Blueprint
# ============================================================================
export_bp = Blueprint("export", __name__, url_prefix="/export_publipostage")

# ============================================================================
# Configuration (FORC√âE PROD)
# ============================================================================
FOLDER_ID_ASSOCIATIONS = os.getenv("FOLDER_ID_ASSOCIATIONS")
FOLDER_ID_BENEVOLES = os.getenv("FOLDER_ID_BENEVOLES")

PUBLIPOSTAGE_DB_PATH = os.getenv("PUBLIPOSTAGE_DB_PATH")
if not PUBLIPOSTAGE_DB_PATH:
    raise RuntimeError("PUBLIPOSTAGE_DB_PATH non d√©fini")

# ============================================================================
# Outils
# ============================================================================
def is_valid_email(email):
    if not isinstance(email, str):
        return False
    email = email.strip()
    if not email or email.lower() == "none":
        return False
    if email.endswith("."):
        return False
    return bool(re.match(r"^[^@\s]+@[^@\s]+\.[a-zA-Z]{2,}$", email))



@export_bp.route("/trigger", methods=["POST"])
def trigger_publipostage_cron():
    try:
        cmd = [
            "/srv/ba38/prod/venv/bin/python",
            "/srv/ba38/scripts_taches/export_publipostage_nuit.py"
        ]

        subprocess.Popen(
            cmd,
            stdout=open("/srv/ba38/prod/logs/cron_publipostage.log", "a"),
            stderr=open("/srv/ba38/prod/logs/cron_publipostage.log", "a"),
            start_new_session=True
        )

        return jsonify({
            "message": "‚è≥ Export publipostage lanc√© (traitement en arri√®re-plan).\n"
                       "Les fichiers seront mis √† jour dans quelques instants."
        })

    except Exception as e:
        return jsonify({
            "message": f"‚ùå Erreur lancement export : {e}"
        }), 500

def open_sheet_with_retry(client, file_id, retries=5):
    """
    Ouvre un Google Sheet avec retry automatique
    en cas d'erreur API (502, timeout, etc.).
    """
    for attempt in range(retries):
        try:
            return client.open_by_key(file_id).sheet1
        except APIError as e:
            wait = 5 * (attempt + 1)
            write_log(
                f"‚ö†Ô∏è Google API erreur (tentative {attempt+1}/{retries}) : {e}"
            )

            if attempt < retries - 1:
                write_log(f"‚è≥ Retry dans {wait}s...")
                time.sleep(wait)
            else:
                write_log("‚ùå √âchec d√©finitif apr√®s retries Google.")
                raise


def export_all_publipostage_job():
    """
    Export publipostage complet ‚Äì version batch / cron (sans Flask).
    Utilise exclusivement la base PROD forc√©e.
    Retourne une liste de messages (summary).
    """
    write_log("üöÄ Export complet publipostage lanc√© (job)")

    client, drive_service, _ = get_google_services()
    if not client or not drive_service:
        raise RuntimeError("Erreur de connexion √† Google Sheets / Drive")

    summary = []
    emails_invalides = {}

    conn = sqlite3.connect(PUBLIPOSTAGE_DB_PATH)
    conn.row_factory = sqlite3.Row
    write_log(f"üîí Connexion forc√©e publipostage : {PUBLIPOSTAGE_DB_PATH}")

    try:
        # ============================================================
        # ASSOCIATIONS ‚Äî Tous les emails
        # ============================================================
        all_columns = [
            "courriel_association",
            "courriel_president",
            "courriel_resp_operationnel",
            "courriel_distribution",
            "courriel_resp_Hysa",
            "courriel_resp_tresorerie",
            "courriel_resp_IE1",
            "courriel_resp_IE2",
        ]

        df_all = pd.read_sql_query(
            f"""
            SELECT nom_association, {','.join(all_columns)}
            FROM associations
            WHERE validite = 'oui'
            """,
            conn
        )

        rows = []
        for _, row in df_all.iterrows():
            nom = str(row["nom_association"])
            for col in all_columns:
                email = row[col]
                if is_valid_email(email):
                    rows.append({
                        "nom_association": nom,
                        "email": str(email).strip()
                    })
                elif email and str(email).strip().lower() != "none":
                    emails_invalides.setdefault(
                        "Publipostage_Assos_Tous_Les_Mails", []
                    ).append(f"{nom} ‚Üí {email}")

        df_final = (
            pd.DataFrame(rows)
            .drop_duplicates(subset=["email"], keep="first")
        )

        summary.append(
            export_dataframe_to_drive(
                df_final,
                "Publipostage_Assos_Tous_Les_Mails",
                client,
                drive_service,
                FOLDER_ID_ASSOCIATIONS
            )
        )

        # ============================================================
        # ASSOCIATIONS ‚Äî Fichiers par champ
        # ============================================================
        simple_fields = [
            "courriel_association",
            "courriel_president",
            "courriel_resp_operationnel",
            "courriel_distribution",
            "courriel_resp_Hysa",
            "courriel_resp_tresorerie",
        ]

        for champ in simple_fields:
            nom_fichier = f"Publipostage_Assos_{champ}"

            df = pd.read_sql_query(
                f"""
                SELECT nom_association, {champ} AS email
                FROM associations
                WHERE validite = 'oui'
                """,
                conn
            )

            df["email"] = df["email"].astype(str).str.strip()

            for _, row in df.iterrows():
                if not is_valid_email(row["email"]) and row["email"].lower() != "none":
                    emails_invalides.setdefault(nom_fichier, []).append(
                        f"{row['nom_association']} ‚Üí {row['email']}"
                    )

            df = df[df["email"].apply(is_valid_email)]
            df = df.drop_duplicates(subset=["email"], keep="first")

            summary.append(
                export_dataframe_to_drive(
                    df,
                    nom_fichier,
                    client,
                    drive_service,
                    FOLDER_ID_ASSOCIATIONS
                )
            )

        # ============================================================
        # ASSOCIATIONS ‚Äî Responsables IE (IE1 + IE2 fusionn√©s)
        # ============================================================
        nom_fichier_ie = "Publipostage_Assos_courriel_resp_IE"

        df_ie = pd.read_sql_query(
            """
            SELECT nom_association, courriel_resp_IE1, courriel_resp_IE2
            FROM associations
            WHERE validite = 'oui'
            """,
            conn
        )

        rows_ie = []
        for _, row in df_ie.iterrows():
            nom = str(row["nom_association"])
            for champ in ["courriel_resp_IE1", "courriel_resp_IE2"]:
                email = row[champ]
                if is_valid_email(email):
                    rows_ie.append({
                        "nom_association": nom,
                        "email": str(email).strip()
                    })
                elif email and str(email).strip().lower() != "none":
                    emails_invalides.setdefault(nom_fichier_ie, []).append(
                        f"{nom} ‚Üí {email}"
                    )

        df_ie_final = (
            pd.DataFrame(rows_ie)
            .drop_duplicates(subset=["email"], keep="first")
        )

        summary.append(
            export_dataframe_to_drive(
                df_ie_final,
                nom_fichier_ie,
                client,
                drive_service,
                FOLDER_ID_ASSOCIATIONS
            )
        )

        # ============================================================
        # B√âN√âVOLES
        # ============================================================
        df_b = pd.read_sql_query(
            """
            SELECT civilite, nom, prenom, email
            FROM benevoles
            """,
            conn
        )

        df_b["email"] = df_b["email"].astype(str).str.strip()
        df_b = df_b[df_b["email"].apply(is_valid_email)]
        df_b = df_b.drop_duplicates(subset=["email"], keep="first")

        summary.append(
            export_dataframe_to_drive(
                df_b,
                "Publipostage_B√©n√©voles",
                client,
                drive_service,
                FOLDER_ID_BENEVOLES
            )
        )

        # ============================================================
        # ASSOCIATIONS ‚Äî BASE MAIL IE
        # ============================================================

        nom_fichier_ie_base = "BASE_MAIL_IE"

        df_ie_base = pd.read_sql_query("""
            SELECT code_VIF, nom_association, responsable_IE,
                tel_resp_IE, courriel_resp_IE1,
                courriel_resp_IE2, CAR
            FROM associations
            WHERE validite = 'oui'
            ORDER BY nom_association
        """, conn)

        for index, row in df_ie_base.iterrows():
            for champ in ["courriel_resp_IE1", "courriel_resp_IE2"]:
                email = row[champ]

                if email and str(email).strip().lower() != "none":
                    if not is_valid_email(email):
                        emails_invalides.setdefault(
                            nom_fichier_ie_base, []
                        ).append(
                            f"{row['nom_association']} ‚Üí {champ} : {email}"
                        )
                        df_ie_base.at[index, champ] = ""
                    else:
                        df_ie_base.at[index, champ] = str(email).strip()
                else:
                    df_ie_base.at[index, champ] = ""

        summary.append(
            export_dataframe_to_drive(
                df_ie_base,
                nom_fichier_ie_base,
                client,
                drive_service,
                FOLDER_ID_ASSOCIATIONS
            )
        )

        # ===============================
        # EMAIL DE SYNTH√àSE
        # ===============================

        if emails_invalides:

            nb_erreurs = sum(len(v) for v in emails_invalides.values())

            corps = (
                "Les adresses suivantes sont invalides et doivent √™tre corrig√©es "
                "dans la fiche association :\n\n"
            )

            for fichier, lignes in emails_invalides.items():
                corps += f"üìÇ {fichier} :\n"
                for ligne in lignes:
                    corps += f"  - {ligne}\n"
                corps += "\n"

            envoyer_mail(
                sujet=f"‚ùå {nb_erreurs} Emails invalides ‚Äì Publipostage üö® [PROD]",
                destinataires=[
                    "ba380.informatique2@banquealimentaire.org",
                    "ba380.secretariat@banquealimentaire.org",
                ],
                texte=corps
            )

            write_log(f"üìß Mail d‚Äôalerte envoy√© ({nb_erreurs} erreurs)")

        write_log("üèÅ Export publipostage termin√©")
        return summary

    finally:
        conn.close()


def list_drive_files(drive_service, container_id):
    try:
        container_id = container_id.strip()

        # Racine drive partag√©
        if container_id.startswith("0A"):
            results = drive_service.files().list(
                corpora="drive",
                driveId=container_id,
                includeItemsFromAllDrives=True,
                supportsAllDrives=True,
                q="trashed=false",
                fields="files(id, name)"
            ).execute()
        # Dossier classique
        else:
            results = drive_service.files().list(
                q=f"'{container_id}' in parents and trashed=false",
                includeItemsFromAllDrives=True,
                supportsAllDrives=True,
                fields="files(id, name)"
            ).execute()

        return results.get("files", [])

    except Exception as e:
        write_log(f"‚ùå Erreur list_drive_files({container_id}) : {e}")
        return []


def get_existing_spreadsheet_id(drive_service, container_id, filename):
    normalized = filename.strip().replace(" ", "_").lower()
    for file in list_drive_files(drive_service, container_id):
        if file["name"].strip().replace(" ", "_").lower() == normalized:
            return file["id"]
    return None


def create_spreadsheet_in_shared_drive(drive_service, folder_id, sheet_name):
    metadata = {
        "name": sheet_name,
        "mimeType": "application/vnd.google-apps.spreadsheet",
        "parents": [folder_id]   # ‚úÖ TOUJOURS
    }

    spreadsheet = drive_service.files().create(
        body=metadata,
        fields="id",
        supportsAllDrives=True
    ).execute()

    return spreadsheet["id"]

def export_dataframe_to_drive(df, sheet_name, client, drive_service, container_id):
    try:
        if "email" in df.columns:
            df = df[df["email"].apply(is_valid_email)]

        if df.empty:
            write_log(f"‚ö†Ô∏è Aucun enregistrement √† exporter pour {sheet_name}")
            return f"{sheet_name} : vide"

        file_id = get_existing_spreadsheet_id(
            drive_service,
            container_id,
            sheet_name
        )

        if file_id:
            drive_service.files().delete(
                fileId=file_id,
                supportsAllDrives=True
            ).execute()
            write_log(f"üóëÔ∏è Ancien fichier supprim√© : {sheet_name}")

        file_id = create_spreadsheet_in_shared_drive(
            drive_service,
            container_id,
            sheet_name
        )

        # üîí ouverture s√©curis√©e
        sheet = open_sheet_with_retry(client, file_id)

        sheet.clear()
        sheet.insert_rows(
            [df.columns.tolist()] + df.values.tolist()
        )

        write_log(f"‚úÖ Export√© : {sheet_name} ({len(df)} lignes)")
        return f"{sheet_name} : {len(df)} lignes"

    except Exception as e:
        write_log(f"‚ùå ERREUR export {sheet_name} : {e}")
        return f"‚ùå {sheet_name} : ERREUR"



# ============================================================================
# ROUTES FLASK
# ============================================================================

@export_bp.route("/all", methods=["POST"])
def export_all_publipostage():
    try:
        summary = export_all_publipostage_job()
        return jsonify({"message": "\n".join(summary)})
    except Exception as e:
        write_log(f"‚ùå Erreur export global : {e}")
        return jsonify({"message": f"‚ùå Erreur : {e}"}), 500


